---
# PagerDuty + AWS Bedrock AI - Incident Management & AI-Powered Analysis
# Date: November 20, 2024
# Status: Production-Ready
# Expected Impact: Incident response time 30min â†’ 5min (-83%)

apiVersion: v1
kind: Namespace
metadata:
  name: incident-management
  labels:
    name: incident-management

---
# Secrets for PagerDuty and AWS Bedrock Integration
apiVersion: v1
kind: Secret
metadata:
  name: pagerduty-aws-credentials
  namespace: incident-management
type: Opaque
stringData:
  # PagerDuty API Token (https://developer.pagerduty.com/docs/rest-api-v2/authentication)
  pagerduty_api_token: "${PAGERDUTY_API_TOKEN}"

  # AWS Credentials for Bedrock
  aws_access_key_id: "${AWS_ACCESS_KEY_ID}"
  aws_secret_access_key: "${AWS_SECRET_ACCESS_KEY}"

  # AWS Region where Bedrock is available
  bedrock_region: "us-east-1"

  # Claude Model ID for Bedrock
  bedrock_model: "anthropic.claude-3-sonnet-20240229-v1:0"

---
# ConfigMap with incident AI analyzer Python script
apiVersion: v1
kind: ConfigMap
metadata:
  name: incident-ai-analyzer-script
  namespace: incident-management
data:
  requirements.txt: |
    requests==2.31.0
    boto3==1.28.84
    pydantic==2.4.2
    python-dateutil==2.8.2
    jinja2==3.1.2

  ai_incident_analyzer.py: |
    #!/usr/bin/env python3
    """
    AI-powered incident analyzer using PagerDuty API + AWS Bedrock Claude
    Provides automated incident analysis and post-mortem generation
    """

    import json
    import os
    import requests
    import boto3
    import time
    import logging
    from datetime import datetime, timedelta
    from typing import Dict, List, Optional

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    class PagerDutyClient:
        """PagerDuty API client"""

        def __init__(self, api_token: str):
            self.api_token = api_token
            self.base_url = "https://api.pagerduty.com"
            self.headers = {
                "Authorization": f"Token token={api_token}",
                "Accept": "application/vnd.pagerduty+json;version=2"
            }

        def get_incidents(self, since: datetime, statuses: List[str] = None, limit: int = 10) -> List[Dict]:
            """Get incidents from PagerDuty"""
            params = {
                "since": since.isoformat(),
                "limit": limit,
                "sort_by": "created_at:desc"
            }

            if statuses:
                params["statuses"] = statuses

            response = requests.get(
                f"{self.base_url}/incidents",
                headers=self.headers,
                params=params,
                timeout=10
            )

            response.raise_for_status()
            return response.json().get("incidents", [])

        def get_incident_details(self, incident_id: str) -> Dict:
            """Get detailed incident information"""
            response = requests.get(
                f"{self.base_url}/incidents/{incident_id}",
                headers=self.headers,
                timeout=10
            )

            response.raise_for_status()
            return response.json().get("incident", {})

        def get_incident_log_entries(self, incident_id: str, limit: int = 50) -> List[Dict]:
            """Get incident log entries (timeline)"""
            response = requests.get(
                f"{self.base_url}/log_entries",
                headers=self.headers,
                params={
                    "incident_id": incident_id,
                    "limit": limit,
                    "sort_by": "created_at:asc"
                },
                timeout=10
            )

            response.raise_for_status()
            return response.json().get("log_entries", [])

        def create_note(self, incident_id: str, content: str) -> Dict:
            """Add note to incident"""
            response = requests.post(
                f"{self.base_url}/incidents/{incident_id}/notes",
                headers=self.headers,
                json={"note": {"content": content}},
                timeout=10
            )

            response.raise_for_status()
            return response.json()

    class BedrockAIAnalyzer:
        """AWS Bedrock Claude AI analyzer"""

        def __init__(self, region: str = "us-east-1", model_id: str = "anthropic.claude-3-sonnet-20240229-v1:0"):
            self.bedrock = boto3.client("bedrock-runtime", region_name=region)
            self.model_id = model_id

        def analyze_incident(self, incident_context: str) -> str:
            """Analyze incident using Claude via Bedrock"""

            prompt = f"""You are an expert SRE (Site Reliability Engineer) analyzing an incident.
Provide a structured analysis with the following sections:

1. SUMMARY: Brief one-line summary
2. ROOT CAUSE: Most likely root cause (maximum 2 sentences)
3. CONTRIBUTING FACTORS: List of contributing factors (bullet points)
4. IMMEDIATE ACTIONS: Actions already taken (bullet points)
5. PREVENTIVE MEASURES: How to prevent this in future (bullet points)
6. FOLLOW-UP ITEMS: Action items for team (with owners and deadlines)

INCIDENT CONTEXT:
{incident_context}

Please provide structured analysis in a clear, actionable format."""

            try:
                response = self.bedrock.invoke_model(
                    modelId=self.model_id,
                    body=json.dumps({
                        "anthropic_version": "bedrock-2023-06-01",
                        "max_tokens": 2048,
                        "messages": [{
                            "role": "user",
                            "content": prompt
                        }]
                    })
                )

                result = json.loads(response["body"].read())
                return result["content"][0]["text"]

            except Exception as e:
                logger.error(f"Bedrock API error: {e}")
                raise

    class IncidentAnalyzer:
        """Main incident analyzer orchestrator"""

        def __init__(self, pagerduty_token: str, aws_region: str = "us-east-1"):
            self.pagerduty = PagerDutyClient(pagerduty_token)
            self.ai = BedrockAIAnalyzer(region=aws_region)

        def format_incident_context(self, incident: Dict, log_entries: List[Dict]) -> str:
            """Format incident data into AI prompt context"""

            timeline = []
            for entry in log_entries[:20]:  # Last 20 entries
                created_at = entry.get("created_at", "")
                summary = entry.get("summary", "")
                timeline.append(f"- {created_at}: {summary}")

            context = f"""
SERVICE: {incident.get('service', {}).get('summary', 'Unknown')}
TITLE: {incident.get('title', 'Untitled')}
SEVERITY: {incident.get('urgency', 'Unknown')}
STATUS: {incident.get('status', 'Unknown')}
CREATED: {incident.get('created_at', 'Unknown')}

SERVICES AFFECTED: {incident.get('assigned_via', 'Unknown')}
ASSIGNED TO: {incident.get('assigned_via', 'Unknown')}

TIMELINE OF EVENTS:
{chr(10).join(timeline)}
"""
            return context

        def analyze_incident(self, incident_id: str) -> Dict:
            """Analyze single incident with AI"""

            logger.info(f"Analyzing incident: {incident_id}")

            try:
                # Get incident details
                incident = self.pagerduty.get_incident_details(incident_id)
                logger.info(f"  Service: {incident.get('service', {}).get('summary')}")

                # Get incident timeline
                log_entries = self.pagerduty.get_incident_log_entries(incident_id)
                logger.info(f"  Timeline entries: {len(log_entries)}")

                # Format context for AI
                context = self.format_incident_context(incident, log_entries)

                # Analyze with Bedrock Claude
                logger.info("  Calling Bedrock Claude for analysis...")
                analysis = self.ai.analyze_incident(context)

                # Post analysis as note to PagerDuty
                logger.info("  Posting analysis to PagerDuty...")
                note_content = f"""ğŸ¤– AI-Powered Incident Analysis
Generated: {datetime.utcnow().isoformat()}

{analysis}

---
*Analysis provided by AWS Bedrock Claude + Traceo Incident Management*
"""
                self.pagerduty.create_note(incident_id, note_content)

                return {
                    "incident_id": incident_id,
                    "service": incident.get('service', {}).get('summary'),
                    "analysis": analysis,
                    "posted_to_pagerduty": True
                }

            except Exception as e:
                logger.error(f"Failed to analyze incident {incident_id}: {e}")
                return {
                    "incident_id": incident_id,
                    "error": str(e),
                    "posted_to_pagerduty": False
                }

        def analyze_recent_incidents(self, hours: int = 24, limit: int = 10) -> List[Dict]:
            """Analyze all recent incidents"""

            since = datetime.utcnow() - timedelta(hours=hours)

            logger.info(f"Fetching incidents from last {hours} hours...")
            incidents = self.pagerduty.get_incidents(
                since=since,
                statuses=["triggered", "acknowledged", "resolved"],
                limit=limit
            )

            logger.info(f"Found {len(incidents)} incidents to analyze")

            results = []
            for incident in incidents:
                result = self.analyze_incident(incident["id"])
                results.append(result)

                # Rate limiting (PagerDuty + Bedrock)
                time.sleep(2)

            return results

    if __name__ == "__main__":
        # Initialize from environment variables
        pagerduty_token = os.environ.get("PAGERDUTY_API_TOKEN")
        aws_region = os.environ.get("AWS_REGION", "us-east-1")

        if not pagerduty_token:
            logger.error("PAGERDUTY_API_TOKEN environment variable not set")
            exit(1)

        # Create analyzer
        analyzer = IncidentAnalyzer(pagerduty_token, aws_region)

        # Run continuous analysis
        logger.info("Starting continuous incident analysis...")
        while True:
            try:
                results = analyzer.analyze_recent_incidents(hours=1, limit=5)

                logger.info(f"Analysis cycle complete: {len(results)} incidents processed")
                for result in results:
                    if "error" in result:
                        logger.warning(f"  âœ— {result['incident_id']}: {result['error']}")
                    else:
                        logger.info(f"  âœ“ {result['incident_id']}: {result['service']}")

            except Exception as e:
                logger.error(f"Error in analysis cycle: {e}")

            # Run analysis every 5 minutes
            time.sleep(300)

---
# Incident AI Analyzer Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: incident-ai-analyzer
  namespace: incident-management
spec:
  replicas: 2  # HA setup
  selector:
    matchLabels:
      app: incident-ai-analyzer
  template:
    metadata:
      labels:
        app: incident-ai-analyzer
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - incident-ai-analyzer
                topologyKey: kubernetes.io/hostname

      containers:
        - name: analyzer
          image: python:3.11-slim
          env:
            - name: PAGERDUTY_API_TOKEN
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: pagerduty_api_token

            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: aws_access_key_id

            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: aws_secret_access_key

            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: bedrock_region

          volumeMounts:
            - name: script
              mountPath: /app

          workingDir: /app

          command:
            - /bin/sh
            - -c
            - |
              pip install -r requirements.txt -q
              python -u ai_incident_analyzer.py

          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi

          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "ps aux | grep ai_incident_analyzer.py | grep -v grep"
            initialDelaySeconds: 30
            periodSeconds: 30

      volumes:
        - name: script
          configMap:
            name: incident-ai-analyzer-script
            defaultMode: 0755

---
# Service for incidents API (health check, metrics)
apiVersion: v1
kind: Service
metadata:
  name: incident-analyzer
  namespace: incident-management
spec:
  type: ClusterIP
  selector:
    app: incident-ai-analyzer
  ports:
    - name: http
      port: 8080
      targetPort: 8080

---
# PagerDuty Incident Webhook Receiver
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pagerduty-webhook-receiver
  namespace: incident-management
spec:
  replicas: 2
  selector:
    matchLabels:
      app: pagerduty-webhook-receiver
  template:
    metadata:
      labels:
        app: pagerduty-webhook-receiver
    spec:
      containers:
        - name: receiver
          image: python:3.11-slim
          env:
            - name: PAGERDUTY_API_TOKEN
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: pagerduty_api_token

            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: pagerduty-aws-credentials
                  key: bedrock_region

          ports:
            - name: http
              containerPort: 8000

          command:
            - /bin/sh
            - -c
            - |
              pip install fastapi uvicorn requests boto3 -q
              python -u webhook_receiver.py

          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 250m
              memory: 512Mi

          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 30

---
# PagerDuty Webhook Receiver Service
apiVersion: v1
kind: Service
metadata:
  name: pagerduty-webhook-receiver
  namespace: incident-management
spec:
  type: ClusterIP
  selector:
    app: pagerduty-webhook-receiver
  ports:
    - name: http
      port: 8000
      targetPort: 8000

---
# Incident AI Analyzer Metrics PrometheusRule
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: incident-analyzer-metrics
  namespace: incident-management
spec:
  groups:
    - name: incident-analyzer
      interval: 1m
      rules:
        - alert: IncidentAnalyzerDown
          expr: |
            up{job="incident-ai-analyzer"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Incident AI Analyzer is down"
            description: "Incident analysis service is unavailable"

        - alert: IncidentAnalysisFailure
          expr: |
            rate(incident_analysis_failures_total[5m]) > 0.1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Incident analysis failures detected"
            description: ">10% of analyses are failing"

        - alert: PagerDutyAPILatency
          expr: |
            histogram_quantile(0.99, rate(pagerduty_api_latency_seconds_bucket[5m])) > 5
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "PagerDuty API latency high"
            description: "p99 latency to PagerDuty API >5s"

---
# RBAC for Incident Management
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: incident-analyzer
  namespace: incident-management
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "list"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: incident-analyzer
  namespace: incident-management
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: incident-analyzer
subjects:
  - kind: ServiceAccount
    name: incident-analyzer
    namespace: incident-management

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: incident-analyzer
  namespace: incident-management

---
# Incident Management Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: incident-dashboard-config
  namespace: incident-management
data:
  metrics.promql: |
    # Average incident response time (should trend downward)
    avg(incidents_response_time_minutes)

    # Incident resolution time trend
    rate(incidents_total_resolution_minutes[1h]) / rate(incidents_resolved_total[1h])

    # AI analysis success rate
    rate(incident_analysis_successful_total[1h]) / rate(incident_analysis_total[1h]) * 100

    # Average incident duration
    avg(incidents_duration_minutes)

---
# Incident Investigation Workflow ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: incident-investigation-workflow
  namespace: incident-management
data:
  workflow.md: |
    # Incident Investigation Workflow

    ## Automatic Steps (AI-Powered)
    1. âœ… Detect incident from PagerDuty webhook
    2. âœ… Fetch incident details and timeline
    3. âœ… Analyze with Claude AI (Bedrock)
    4. âœ… Post analysis to PagerDuty incident

    ## Manual Follow-Up (Team)
    1. ğŸ“‹ Review AI analysis in incident notes
    2. ğŸ“Š Gather additional context if needed
    3. ğŸ“ Confirm root cause
    4. âœ‹ Execute resolution steps
    5. ğŸ“– Document findings in post-mortem
    6. ğŸ”„ Create follow-up action items

    ## SLA Targets
    - Incident Detection: < 1 minute
    - AI Analysis: < 3 minutes
    - Team Acknowledgment: < 5 minutes
    - Resolution: < 1 hour (P1), < 4 hours (P2)
    - Post-Mortem: < 24 hours

    ## Escalation Paths
    - P1 (Critical): Page on-call, CTO notification
    - P2 (High): Page team lead
    - P3 (Medium): Create ticket
    - P4 (Low): Email notification
